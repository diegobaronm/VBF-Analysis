{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a template of the weighted average of two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "from ROOT import gStyle\n",
    "import numpy as np\n",
    "import ctypes\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def model_uncern(covariance_matrix,x):\n",
    "    var_a = covariance_matrix[0][0]\n",
    "    var_b = covariance_matrix[1][1]\n",
    "    var_c = covariance_matrix[2][2]\n",
    "    \n",
    "    cov_ab = covariance_matrix[0][1]\n",
    "    cov_ac = covariance_matrix[0][2]\n",
    "    cov_bc = covariance_matrix[1][2]\n",
    "    \n",
    "    diagonal_term = var_a*(x**4) + var_b*(x**2) + var_c\n",
    "    no_diagonal_term = 2*cov_ab*(x**3) + 2*cov_ac*(x**2) + 2*cov_bc*x\n",
    "    \n",
    "    return np.sqrt(diagonal_term+no_diagonal_term)\n",
    "\n",
    "def parabolic_shape(mjj,parameters):\n",
    "    a = parameters[0]\n",
    "    b = parameters[1]\n",
    "    c = parameters[2]\n",
    "    return a*mjj*mjj+b*mjj+c\n",
    "\n",
    "model_uncer = np.vectorize(model_uncern)\n",
    "parabolic_shape = np.vectorize(parabolic_shape,excluded=['parameters'])\n",
    "\n",
    "fitParams = {\"Sherpa\": [ 1.31867345e-07, -6.91194368e-04,  1.49568233e+00], \n",
    "              \"MG\" : [ 1.35194973e-07, -5.44814667e-04,  9.89623841e-01] }\n",
    "\n",
    "covarianceMatrix =  {\"Sherpa\" : [[ 1.19177067e-17, -2.94876918e-14,  1.41446066e-11],\n",
    "                               [-2.94876918e-14,  8.14817316e-11, -4.30728335e-08],\n",
    "                               [ 1.41446066e-11, -4.30728335e-08,  2.66545658e-05]],\n",
    "                    \"MG\" : [[ 6.10103774e-18, -1.39152060e-14,  6.28353598e-12],\n",
    "                           [-1.39152060e-14,  3.55524563e-11, -1.77055103e-08],\n",
    "                           [ 6.28353598e-12, -1.77055103e-08,  1.02381778e-05]]}\n",
    "\n",
    "def scaleBinUncertainty(histogram,sampleName):\n",
    "    \n",
    "    sampleType = \"MG\"\n",
    "    if \"Sherpa\" in sampleName:\n",
    "        sampleType = \"Sherpa\"\n",
    "    \n",
    "    for i in range(1,histogram.GetNbinsX()+1):\n",
    "        x = histogram.GetBinCenter(i)\n",
    "        error = histogram.GetBinError(i)\n",
    "        rw = parabolic_shape(x,parameters=fitParams[sampleType])\n",
    "        rw_error = model_uncern(covarianceMatrix[sampleType],x)\n",
    "        newError = np.sqrt(error**2 + ((rw_error/rw)**2)*(error**2))\n",
    "        histogram.SetBinError(i,newError)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/diegomac/Documents/HEP/VBF-Analysis/Scripts/')\n",
    "\n",
    "\n",
    "############# CONFIGURING THE JOB ###########################\n",
    "samples_path = \"/Users/diegomac/Documents/HEP/VBF-Analysis/Zll/High-Mass/SR/\"\n",
    "sample1_name = \"Zll_SherpaRW\"\n",
    "sample2_name = \"Zll_MGRW\"\n",
    "\n",
    "qcd_1=0.923\n",
    "qcd_2=0.968\n",
    "\n",
    "fs_name = \"Zll\"\n",
    "EWSampleUsedForExtraction = \"PoPy\"\n",
    "EWSampleUsedForExtraction = \"_EW-\"+EWSampleUsedForExtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_bjets\n",
      "lepiso\n",
      "n_jets_interval\n",
      "lep1_eta_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n",
      "lep2_eta_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n",
      "ljet0_eta_basic_cuts_ptl\n",
      "ljet1_eta_basic_cuts_ptl\n",
      "delta_R_leplep_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n",
      "delta_R_lep1jet_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n",
      "delta_R_lep2jet_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n",
      "delta_phi\n",
      "lep1_pt\n",
      "lep2_pt\n",
      "ljet0_pt\n",
      "ljet1_pt\n",
      "pt_bal\n",
      "Z_centrality\n",
      "delta_y\n",
      "inv_mass\n",
      "mass_jj\n",
      "Z_pt_reco_basic_cuts_ptl\n",
      "vec_sum_pt_jets_basic_cuts_ptl\n",
      "ratio_zpt_sumjetpt_basic_cuts_ptl\n",
      "met_basic_dphi_drap_btag_iso_pt1_pt2_j1pt_j2pt_ptbal_mjj_nji_zcen_mass_ptl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from histogramHelpers import histogramsHighStatsZtautau,histogramsLowStatsZtautau,histogramsHighStatsZll,histogramsLowStatsZll\n",
    "from histogramHelpers import biner,normalization\n",
    "\n",
    "# Define what channel histograms to produce\n",
    "histos = histogramsLowStatsZll\n",
    "\n",
    "r.TH1.AddDirectory(r.kFALSE)\n",
    "file1 = r.TFile.Open(samples_path+sample1_name+'.root')\n",
    "file2 = r.TFile.Open(samples_path+sample2_name+'.root')\n",
    "\n",
    "myFile =r.TFile.Open(fs_name+\"_Average\"+EWSampleUsedForExtraction+\".root\", \"RECREATE\")\n",
    "r.TH1.AddDirectory(r.kFALSE)    \n",
    "\n",
    "for histo,value in histos.items():\n",
    "    print(histo)\n",
    "    h1 = file1.Get(histo)\n",
    "    h2 = file2.Get(histo)\n",
    "    \n",
    "    h1.Scale(qcd_1)\n",
    "    h2.Scale(qcd_2)\n",
    "    \n",
    "    if len(value)>2:\n",
    "    \n",
    "        rebining=biner(histos[histo][0],histos[histo][1],h1)\n",
    "        nb=len(rebining)-1\n",
    "        h1=h1.Rebin(nb,histo,rebining)\n",
    "        h2=h2.Rebin(nb,histo,rebining)\n",
    "        \n",
    "        if \"mass_jj\" in histo:\n",
    "            scaleBinUncertainty(h1,sample1_name)\n",
    "            scaleBinUncertainty(h2,sample2_name)\n",
    "        \n",
    "        #h1.Scale(1.0/h1.Integral(1,-1))\n",
    "        #h2.Scale(1.0/h2.Integral(1,-1))\n",
    "\n",
    "        #hist_list=[h1,h2]\n",
    "        #normalization(hist_list,total_histos[histo][2])\n",
    "    \n",
    "    h1.SetBit(r.TH1.kIsAverage)\n",
    "    h2.SetBit(r.TH1.kIsAverage)\n",
    "    \n",
    "    final_hist = h1.Clone()\n",
    "    final_hist.Add(h2)\n",
    "\n",
    "    myFile.WriteObject(final_hist,histo)\n",
    "\n",
    "myFile.Close()\n",
    "\n",
    "os.system(\"mv \"+fs_name+\"_Average\"+EWSampleUsedForExtraction+\".root \"+samples_path+\"/\"+fs_name+\"_Average\"+EWSampleUsedForExtraction+\".root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
